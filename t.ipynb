{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import sys\n",
    "\n",
    "import numpy\n",
    "from tqdm import tqdm\n",
    "import common as com\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "\n",
    "param = com.yaml_load()\n",
    "\n",
    "########################################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "########################################################################\n",
    "# visualizer\n",
    "########################################################################\n",
    "class visualizer(object):\n",
    "    def __init__(self):\n",
    "        import matplotlib.pyplot as plt\n",
    "        self.plt = plt\n",
    "        self.fig = self.plt.figure(figsize=(30, 10))\n",
    "        self.plt.subplots_adjust(wspace=0.3, hspace=0.3)\n",
    "\n",
    "    def loss_plot(self, loss, val_loss):\n",
    "        \"\"\"\n",
    "        Plot loss curve.\n",
    "        loss : list [ float ]\n",
    "            training loss time series.\n",
    "        val_loss : list [ float ]\n",
    "            validation loss time series.\n",
    "        return   : None\n",
    "        \"\"\"\n",
    "        ax = self.fig.add_subplot(1, 1, 1)\n",
    "        ax.cla()\n",
    "        ax.plot(loss)\n",
    "        ax.plot(val_loss)\n",
    "        #设置y轴范围\n",
    "        #self.plt.ylim(-5,100)\n",
    "        ax.set_title(\"Model loss\")\n",
    "        ax.set_xlabel(\"Epoch\")\n",
    "        ax.set_ylabel(\"Loss\")\n",
    "        ax.legend([\"Train\", \"Validation\"], loc=\"upper right\")\n",
    "\n",
    "    def save_figure(self, name):\n",
    "        \"\"\"\n",
    "        Save figure.\n",
    "        name : str\n",
    "            save png file path.\n",
    "        return : None\n",
    "        \"\"\"\n",
    "        self.plt.savefig(name)\n",
    "\n",
    "\n",
    "########################################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def list_to_vector_array(file_list,\n",
    "                         msg=\"calc...\",\n",
    "                         n_mels=64,\n",
    "                         frames=5,\n",
    "                         n_fft=1024,\n",
    "                         hop_length=512,\n",
    "                         power=2.0):\n",
    "    \"\"\"\n",
    "    convert the file_list to a vector array.\n",
    "    file_to_vector_array() is iterated, and the output vector array is concatenated.\n",
    "    file_list : list [ str ]\n",
    "        .wav filename list of dataset\n",
    "    msg : str ( default = \"calc...\" )\n",
    "        description for tqdm.\n",
    "        this parameter will be input into \"desc\" param at tqdm.\n",
    "    return : numpy.array( numpy.array( float ) )\n",
    "        vector array for training (this function is not used for test.)\n",
    "        * dataset.shape = (number of feature vectors, dimensions of feature vectors)\n",
    "    \"\"\"\n",
    "    # calculate the number of dimensions\n",
    "    dims = n_mels * frames\n",
    "\n",
    "    # iterate file_to_vector_array()\n",
    "    for idx in tqdm(range(len(file_list)), desc=msg):\n",
    "        vector_array = com.file_to_vector_array(file_list[idx],\n",
    "                                                n_mels=n_mels,\n",
    "                                                frames=frames,\n",
    "                                                n_fft=n_fft,\n",
    "                                                hop_length=hop_length,\n",
    "                                                power=power)\n",
    "        if idx == 0:\n",
    "            dataset = numpy.zeros((vector_array.shape[0] * len(file_list), dims), float)\n",
    "        dataset[vector_array.shape[0] * idx: vector_array.shape[0] * (idx + 1), :] = vector_array\n",
    "\n",
    "    return dataset\n",
    "\n",
    "def file_list_generator(target_dir,\n",
    "                        dir_name=\"train\",\n",
    "                        ext=\"wav\"):\n",
    "    \"\"\"\n",
    "    target_dir : str\n",
    "        base directory path of the dev_data or eval_data\n",
    "    dir_name : str (default=\"train\")\n",
    "        directory name containing training data\n",
    "    ext : str (default=\"wav\")\n",
    "        file extension of audio files\n",
    "    return :\n",
    "        train_files : list [ str ]\n",
    "            file list for training\n",
    "    \"\"\"\n",
    "    com.logger.info(\"target_dir : {}\".format(target_dir))\n",
    "\n",
    "    # generate training list\n",
    "    training_list_path = os.path.abspath(\"{dir}/{dir_name}/*.{ext}\".format(dir=target_dir, dir_name=dir_name, ext=ext))\n",
    "    files = sorted(glob.glob(training_list_path))\n",
    "    if len(files) == 0:\n",
    "        com.logger.exception(\"no_wav_file!!\")\n",
    "\n",
    "    com.logger.info(\"train_file num : {num}\".format(num=len(files)))\n",
    "    return files\n",
    "\n",
    "def fetch_dataloaders(files,radio = 0.9,batchsize=512):\n",
    "    len_d = len(files)\n",
    "    num_sample_train = int(len_d * radio)\n",
    "    index = list(range(len_d))\n",
    "    random.shuffle(files)\n",
    "    train = list(files[0:num_sample_train])\n",
    "    val = list(files[num_sample_train+1:])\n",
    "    train_data_loader = torch.utils.data.DataLoader(dataset=train, batch_size=batchsize, shuffle=True)\n",
    "    val_data_loader = torch.utils.data.DataLoader(dataset=val, batch_size=batchsize, shuffle=True)\n",
    "    loader = {}\n",
    "    loader['train'] = train_data_loader\n",
    "    loader['val'] = val_data_loader\n",
    "    return loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "########################################################################\n",
    "#pytorch 模型相关\n",
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AutoEncoder, self).__init__()\n",
    "\n",
    "        # Encoder\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(640, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 32),\n",
    "        )\n",
    "\n",
    "        # Decoder\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(32, 32),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 64),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 640)\n",
    "        )\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        codes = self.encoder(inputs)\n",
    "        decoded = self.decoder(codes)\n",
    "\n",
    "        return codes, decoded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-12 20:52:28,758 - INFO - target_dir : ../file/noise_detect\n",
      "2021-10-12 20:52:28,760 - INFO - train_file num : 200\n",
      "2021-10-12 20:52:28,761 - INFO - files num 200\n",
      "generate train_dataset: 100%|██████████| 200/200 [00:02<00:00, 78.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============== MODEL TRAINING ==============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-12 20:52:31,388 - INFO - train_data num 124400\n",
      "100%|██████████| 219/219 [00:08<00:00, 26.96it/s]\n",
      "100%|██████████| 25/25 [00:00<00:00, 56.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(508.3978, grad_fn=<MseLossBackward>) 0 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 219/219 [00:08<00:00, 25.98it/s]\n",
      "100%|██████████| 25/25 [00:00<00:00, 56.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(116.8593, grad_fn=<MseLossBackward>) 1 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 219/219 [00:07<00:00, 27.55it/s]\n",
      "100%|██████████| 25/25 [00:00<00:00, 58.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(146.5325, grad_fn=<MseLossBackward>) 2 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 219/219 [00:07<00:00, 27.86it/s]\n",
      "100%|██████████| 25/25 [00:00<00:00, 57.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(60.2010, grad_fn=<MseLossBackward>) 3 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 219/219 [00:08<00:00, 27.30it/s]\n",
      "100%|██████████| 25/25 [00:00<00:00, 58.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(93.8054, grad_fn=<MseLossBackward>) 4 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 219/219 [00:08<00:00, 27.16it/s]\n",
      "100%|██████████| 25/25 [00:00<00:00, 57.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(42.5417, grad_fn=<MseLossBackward>) 5 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 219/219 [00:07<00:00, 27.39it/s]\n",
      "100%|██████████| 25/25 [00:00<00:00, 57.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(50.7467, grad_fn=<MseLossBackward>) 6 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 219/219 [00:07<00:00, 28.57it/s]\n",
      "100%|██████████| 25/25 [00:00<00:00, 59.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(44.3491, grad_fn=<MseLossBackward>) 7 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 219/219 [00:07<00:00, 28.20it/s]\n",
      "100%|██████████| 25/25 [00:00<00:00, 58.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(47.9788, grad_fn=<MseLossBackward>) 8 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 219/219 [00:07<00:00, 27.85it/s]\n",
      "100%|██████████| 25/25 [00:00<00:00, 48.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(70.1520, grad_fn=<MseLossBackward>) 9 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ZTTTX\\Programing\\Anaconda\\envs\\noise_detect\\lib\\site-packages\\torch\\serialization.py:292: UserWarning: Couldn't retrieve source code for container of type AutoEncoder. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "C:\\ZTTTX\\Programing\\Anaconda\\envs\\noise_detect\\lib\\site-packages\\torch\\serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Sequential. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "C:\\ZTTTX\\Programing\\Anaconda\\envs\\noise_detect\\lib\\site-packages\\torch\\serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Linear. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "C:\\ZTTTX\\Programing\\Anaconda\\envs\\noise_detect\\lib\\site-packages\\torch\\serialization.py:292: UserWarning: Couldn't retrieve source code for container of type BatchNorm1d. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "C:\\ZTTTX\\Programing\\Anaconda\\envs\\noise_detect\\lib\\site-packages\\torch\\serialization.py:292: UserWarning: Couldn't retrieve source code for container of type ReLU. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============== END TRAINING ==============\n"
     ]
    }
   ],
   "source": [
    "\n",
    "########################################################################\n",
    "# main train.py\n",
    "########################################################################\n",
    "if __name__ == \"__main__\":\n",
    "    # check mode\n",
    "    # \"development\": mode == True\n",
    "    # \"evaluation\": mode == False\n",
    "    #mode = com.command_line_chk()\n",
    "    #if mode is None:\n",
    "    #    sys.exit(-1)\n",
    "\n",
    "    # make output directory\n",
    "    #os.makedirs(param[\"model_directory\"], exist_ok=True)\n",
    "\n",
    "    # initialize the visualizer\n",
    "    #visualizer = visualizer()\n",
    "\n",
    "    # load base_directory list\n",
    "    #dirs = com.select_dirs(param=param, mode=mode)\n",
    "    # loop of the base directory\n",
    "    #for idx, target_dir in enumerate(dirs):\n",
    "\n",
    "    # set path\n",
    "    train_dir = '../file/noise_detect'\n",
    "    files = file_list_generator(train_dir,dir_name=\"train\")\n",
    "    com.logger.info('files num {num}'.format(num=len(files)))\n",
    "    train_data = list_to_vector_array(files,\n",
    "                                        msg=\"generate train_dataset\",\n",
    "                                        n_mels=param[\"feature\"][\"n_mels\"],\n",
    "                                        frames=param[\"feature\"][\"frames\"],\n",
    "                                        n_fft=param[\"feature\"][\"n_fft\"],\n",
    "                                        hop_length=param[\"feature\"][\"hop_length\"],\n",
    "                                        power=param[\"feature\"][\"power\"])\n",
    "    # train model\n",
    "    print(\"============== MODEL TRAINING ==============\")\n",
    "    train_data = torch.Tensor(train_data)\n",
    "    com.logger.info('train_data num {num}'.format(num=len(train_data)))\n",
    "    train_loader = fetch_dataloaders(train_data,radio = 0.9,batchsize = 512)\n",
    "    model = AutoEncoder()\n",
    "    model.train()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    loss_func = nn.MSELoss()\n",
    "    loss_his = []\n",
    "    val_loss_his = []\n",
    "\n",
    "    for epoch in range(10):\n",
    "        losses=[]\n",
    "        for data in tqdm(train_loader[\"train\"]):\n",
    "            optimizer.zero_grad()\n",
    "            inputs = data\n",
    "            feature,y = model(inputs)\n",
    "            loss = loss_func(y, inputs)\n",
    "            losses.append(loss.data)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        numm = numpy.mean(losses)\n",
    "        loss_his.append(numpy.mean(losses))\n",
    "        val_losses=[]\n",
    "        for data in tqdm(train_loader[\"val\"]):\n",
    "            inputs = data\n",
    "            feature,y = model(inputs)\n",
    "            loss = loss_func(y, inputs)\n",
    "            val_losses.append(loss.data)\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "        val_loss_his.append(numpy.mean(val_losses))\n",
    "        print(loss, epoch, \"\\n\")\n",
    "\n",
    "    \n",
    "    torch.save(model, 'model/model.pkl')\n",
    "    visualizer = visualizer()\n",
    "    visualizer.loss_plot(loss_his, val_loss_his)\n",
    "    visualizer.save_figure('loss_his.png')\n",
    "    print(\"============== END TRAINING ==============\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "features = []\n",
    "for data in tqdm(train_loader[\"train\"]):\n",
    "    inputs = data\n",
    "    feature, y = model(inputs)\n",
    "    features.append(feature)\n",
    "features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'DataLoader' object is not an iterator",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-f1bd5472eb33>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"train\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"train\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mfeature\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeature\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'DataLoader' object is not an iterator"
     ]
    }
   ],
   "source": [
    "data=train_loader[\"train\"]\n",
    "inputs = next(train_loader[\"train\"])\n",
    "feature,y=model(inputs)\n",
    "print(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c0c2945573aa59c6a6573181f2c456b961af40bf85fd5f702d7d7d22d6c12cb8"
  },
  "kernelspec": {
   "display_name": "Python 3.6.13 64-bit ('noise_detect': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
