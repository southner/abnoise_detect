{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'librosa'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-34582b0395dd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtqdm\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mcommon\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ztttx\\Desktop\\workspace\\abnoise_detect\\noise_detect\\common.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# additional\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'librosa'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import sys\n",
    "\n",
    "import numpy\n",
    "from tqdm import tqdm\n",
    "import common as com\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "\n",
    "########################################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################\n",
    "# visualizer\n",
    "########################################################################\n",
    "class visualizer(object):\n",
    "    def __init__(self):\n",
    "        import matplotlib.pyplot as plt\n",
    "        self.plt = plt\n",
    "        self.fig = self.plt.figure(figsize=(30, 10))\n",
    "        self.plt.subplots_adjust(wspace=0.3, hspace=0.3)\n",
    "\n",
    "    def loss_plot(self, loss, val_loss):\n",
    "        \"\"\"\n",
    "        Plot loss curve.\n",
    "        loss : list [ float ]\n",
    "            training loss time series.\n",
    "        val_loss : list [ float ]\n",
    "            validation loss time series.\n",
    "        return   : None\n",
    "        \"\"\"\n",
    "        ax = self.fig.add_subplot(1, 1, 1)\n",
    "        ax.cla()\n",
    "        ax.plot(loss)\n",
    "        ax.plot(val_loss)\n",
    "        #设置y轴范围\n",
    "        #self.plt.ylim(-5,100)\n",
    "        ax.set_title(\"Model loss\")\n",
    "        ax.set_xlabel(\"Epoch\")\n",
    "        ax.set_ylabel(\"Loss\")\n",
    "        ax.legend([\"Train\", \"Validation\"], loc=\"upper right\")\n",
    "\n",
    "    def save_figure(self, name):\n",
    "        \"\"\"\n",
    "        Save figure.\n",
    "        name : str\n",
    "            save png file path.\n",
    "        return : None\n",
    "        \"\"\"\n",
    "        self.plt.savefig(name)\n",
    "\n",
    "\n",
    "########################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def list_to_vector_array(file_list,\n",
    "                         msg=\"calc...\",\n",
    "                         n_mels=64,\n",
    "                         frames=5,\n",
    "                         n_fft=1024,\n",
    "                         hop_length=512,\n",
    "                         power=2.0):\n",
    "    \"\"\"\n",
    "    convert the file_list to a vector array.\n",
    "    file_to_vector_array() is iterated, and the output vector array is concatenated.\n",
    "    file_list : list [ str ]\n",
    "        .wav filename list of dataset\n",
    "    msg : str ( default = \"calc...\" )\n",
    "        description for tqdm.\n",
    "        this parameter will be input into \"desc\" param at tqdm.\n",
    "    return : numpy.array( numpy.array( float ) )\n",
    "        vector array for training (this function is not used for test.)\n",
    "        * dataset.shape = (number of feature vectors, dimensions of feature vectors)\n",
    "    \"\"\"\n",
    "    # calculate the number of dimensions\n",
    "    dims = n_mels * frames\n",
    "\n",
    "    # iterate file_to_vector_array()\n",
    "    for idx in tqdm(range(len(file_list)), desc=msg):\n",
    "        vector_array = com.file_to_vector_array(file_list[idx],\n",
    "                                                n_mels=n_mels,\n",
    "                                                frames=frames,\n",
    "                                                n_fft=n_fft,\n",
    "                                                hop_length=hop_length,\n",
    "                                                power=power)\n",
    "        if idx == 0:\n",
    "            dataset = numpy.zeros((vector_array.shape[0] * len(file_list), dims), float)\n",
    "        dataset[vector_array.shape[0] * idx: vector_array.shape[0] * (idx + 1), :] = vector_array\n",
    "\n",
    "    return dataset\n",
    "\n",
    "def file_list_generator(target_dir,\n",
    "                        dir_name=\"train\",\n",
    "                        ext=\"wav\"):\n",
    "    \"\"\"\n",
    "    target_dir : str\n",
    "        base directory path of the dev_data or eval_data\n",
    "    dir_name : str (default=\"train\")\n",
    "        directory name containing training data\n",
    "    ext : str (default=\"wav\")\n",
    "        file extension of audio files\n",
    "    return :\n",
    "        train_files : list [ str ]\n",
    "            file list for training\n",
    "    \"\"\"\n",
    "    com.logger.info(\"target_dir : {}\".format(target_dir+dir_name))\n",
    "\n",
    "    # generate training list\n",
    "    training_list_path = os.path.abspath(\"{dir}/{dir_name}/*.{ext}\".format(dir=target_dir, dir_name=dir_name, ext=ext))\n",
    "    files = sorted(glob.glob(training_list_path))\n",
    "    if len(files) == 0:\n",
    "        com.logger.exception(\"no_wav_file!!\")\n",
    "\n",
    "    com.logger.info(\"train_file num : {num}\".format(num=len(files)))\n",
    "    return files\n",
    "\n",
    "def fetch_dataloaders(files,radio = 0.9,batchsize=512):\n",
    "    len_d = len(files)\n",
    "    num_sample_train = int(len_d * radio)\n",
    "    index = list(range(len_d))\n",
    "    random.shuffle(files)\n",
    "    train = list(files[0:num_sample_train])\n",
    "    val = list(files[num_sample_train+1:])\n",
    "    train_data_loader = torch.utils.data.DataLoader(dataset=train, batch_size=batchsize, shuffle=True)\n",
    "    val_data_loader = torch.utils.data.DataLoader(dataset=val, batch_size=batchsize, shuffle=True)\n",
    "    loader = {}\n",
    "    loader['train'] = train_data_loader\n",
    "    loader['val'] = val_data_loader\n",
    "    return loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "########################################################################\n",
    "#pytorch 模型相关\n",
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AutoEncoder, self).__init__()\n",
    "\n",
    "        # Encoder\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(6400, 1280),\n",
    "            nn.BatchNorm1d(1280),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1280, 640),\n",
    "            nn.BatchNorm1d(640),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(640, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 32),\n",
    "        )\n",
    "\n",
    "        # Decoder\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(32, 32),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 64),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 640),\n",
    "            nn.BatchNorm1d(640),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(640, 1280),\n",
    "            nn.BatchNorm1d(1280),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1280, 6400),\n",
    "        )\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        codes = self.encoder(inputs)\n",
    "        decoded = self.decoder(codes)\n",
    "\n",
    "        return codes, decoded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-21 15:41:00,540 - INFO - target_dir : ../file/noise_detecttrain\n",
      "2021-10-21 15:41:00,543 - INFO - train_file num : 200\n",
      "2021-10-21 15:41:00,544 - INFO - files num 200\n",
      "generate train_dataset: 100%|██████████| 200/200 [00:03<00:00, 52.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============== MODEL TRAINING ==============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-21 15:41:04,395 - INFO - train_data num 11800\n",
      "2021-10-21 15:41:04,602 - INFO - epoch = 10\n",
      "100%|██████████| 21/21 [00:00<00:00, 28.64it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 52.58it/s]\n",
      "2021-10-21 15:41:05,403 - INFO - loss:356.1449890136719 epoch:0\n",
      "100%|██████████| 21/21 [00:00<00:00, 29.07it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 53.52it/s]\n",
      "2021-10-21 15:41:06,188 - INFO - loss:273.4341125488281 epoch:1\n",
      "100%|██████████| 21/21 [00:00<00:00, 29.54it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 51.84it/s]\n",
      "2021-10-21 15:41:06,961 - INFO - loss:262.7305603027344 epoch:2\n",
      "100%|██████████| 21/21 [00:00<00:00, 27.77it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 57.64it/s]\n",
      "2021-10-21 15:41:07,777 - INFO - loss:208.458251953125 epoch:3\n",
      "100%|██████████| 21/21 [00:00<00:00, 28.67it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 61.17it/s]\n",
      "2021-10-21 15:41:08,563 - INFO - loss:179.7202606201172 epoch:4\n",
      "100%|██████████| 21/21 [00:00<00:00, 30.15it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 54.50it/s]\n",
      "2021-10-21 15:41:09,320 - INFO - loss:145.5096893310547 epoch:5\n",
      "100%|██████████| 21/21 [00:00<00:00, 27.93it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 53.82it/s]\n",
      "2021-10-21 15:41:10,135 - INFO - loss:117.11153411865234 epoch:6\n",
      "100%|██████████| 21/21 [00:00<00:00, 28.96it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 55.51it/s]\n",
      "2021-10-21 15:41:10,919 - INFO - loss:129.69229125976562 epoch:7\n",
      "100%|██████████| 21/21 [00:00<00:00, 30.38it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 49.14it/s]\n",
      "2021-10-21 15:41:11,679 - INFO - loss:94.66033172607422 epoch:8\n",
      "100%|██████████| 21/21 [00:00<00:00, 29.63it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 65.16it/s]\n",
      "2021-10-21 15:41:12,440 - INFO - loss:83.38114166259766 epoch:9\n",
      "C:\\ZTTTX\\Programing\\Anaconda\\envs\\noise_detect\\lib\\site-packages\\torch\\serialization.py:292: UserWarning: Couldn't retrieve source code for container of type AutoEncoder. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "C:\\ZTTTX\\Programing\\Anaconda\\envs\\noise_detect\\lib\\site-packages\\torch\\serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Sequential. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "C:\\ZTTTX\\Programing\\Anaconda\\envs\\noise_detect\\lib\\site-packages\\torch\\serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Linear. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "C:\\ZTTTX\\Programing\\Anaconda\\envs\\noise_detect\\lib\\site-packages\\torch\\serialization.py:292: UserWarning: Couldn't retrieve source code for container of type BatchNorm1d. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "C:\\ZTTTX\\Programing\\Anaconda\\envs\\noise_detect\\lib\\site-packages\\torch\\serialization.py:292: UserWarning: Couldn't retrieve source code for container of type ReLU. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============== END TRAINING ==============\n"
     ]
    }
   ],
   "source": [
    "\n",
    "########################################################################\n",
    "# \n",
    "########################################################################\n",
    "if __name__ == \"__main__\":\n",
    "    param = com.yaml_load()\n",
    "    files = file_list_generator(param[\"train_dictionary\"],dir_name=\"train\")\n",
    "    com.logger.info('files num {num}'.format(num=len(files)))\n",
    "    train_data = list_to_vector_array(files,\n",
    "                                        msg=\"generate train_dataset\",\n",
    "                                        n_mels=param[\"feature\"][\"n_mels\"],\n",
    "                                        frames=param[\"feature\"][\"frames\"],\n",
    "                                        n_fft=param[\"feature\"][\"n_fft\"],\n",
    "                                        hop_length=param[\"feature\"][\"hop_length\"],\n",
    "                                        power=param[\"feature\"][\"power\"])\n",
    "    # train model\n",
    "    print(\"============== MODEL TRAINING ==============\")\n",
    "    train_data = torch.Tensor(train_data)\n",
    "    com.logger.info('train_data num {num}'.format(num=len(train_data)))\n",
    "    train_loader = fetch_dataloaders(train_data,radio = 0.9,batchsize = param[\"batch_size\"])\n",
    "    model = AutoEncoder()\n",
    "    model.train()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    loss_func = nn.MSELoss()\n",
    "    loss_his = []\n",
    "    val_loss_his = []\n",
    "    com.logger.info(\"epoch = {}\".format(param[\"epoch\"]))\n",
    "    for epoch in range(param[\"epoch\"]):\n",
    "        losses=[]\n",
    "        for data in tqdm(train_loader[\"train\"]):\n",
    "            optimizer.zero_grad()\n",
    "            inputs = data\n",
    "            feature,y = model(inputs)\n",
    "            loss = loss_func(y, inputs)\n",
    "            losses.append(loss.data)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        loss_his.append(numpy.mean(losses))\n",
    "        val_losses=[]\n",
    "        for data in tqdm(train_loader[\"val\"]):\n",
    "            inputs = data\n",
    "            feature,y = model(inputs)\n",
    "            loss = loss_func(y, inputs)\n",
    "            val_losses.append(loss.data)\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "        val_loss_his.append(numpy.mean(val_losses))\n",
    "        com.logger.info(\"loss:{} epoch:{}\".format(loss,epoch))\n",
    "\n",
    "    \n",
    "    torch.save(model, param[\"model_file\"])\n",
    "    one_visualizer = visualizer()\n",
    "    one_visualizer.loss_plot(loss_his, val_loss_his)\n",
    "    one_visualizer.save_figure(r'pic/train/'+\"debug_tag{}_\".format(str(param[\"debug_tag\"]))+\"trainloss_his.png\")\n",
    "    print(\"============== END TRAINING ==============\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21/21 [00:00<00:00, 37.55it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "features = []\n",
    "for data in tqdm(train_loader[\"train\"]):\n",
    "    inputs = data\n",
    "    feature, y = model(inputs)\n",
    "    for one_feature in feature:\n",
    "        features.append(one_feature)\n",
    "numpy.save(param[\"normal_feature_dic\"],numpy.array(features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e15f3b4bf130e08a64522271bec0f1c44543d81424e1d59960006efbf446c981"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
