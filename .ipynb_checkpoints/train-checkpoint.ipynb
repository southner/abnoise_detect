{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import sys\n",
    "\n",
    "import numpy\n",
    "from tqdm import tqdm\n",
    "import common as com\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "\n",
    "########################################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################\n",
    "# visualizer\n",
    "########################################################################\n",
    "class visualizer(object):\n",
    "    def __init__(self):\n",
    "        import matplotlib.pyplot as plt\n",
    "        self.plt = plt\n",
    "        self.fig = self.plt.figure(figsize=(30, 10))\n",
    "        self.plt.subplots_adjust(wspace=0.3, hspace=0.3)\n",
    "\n",
    "    def loss_plot(self, loss, val_loss):\n",
    "        \"\"\"\n",
    "        Plot loss curve.\n",
    "        loss : list [ float ]\n",
    "            training loss time series.\n",
    "        val_loss : list [ float ]\n",
    "            validation loss time series.\n",
    "        return   : None\n",
    "        \"\"\"\n",
    "        ax = self.fig.add_subplot(1, 1, 1)\n",
    "        ax.cla()\n",
    "        ax.plot(loss)\n",
    "        ax.plot(val_loss)\n",
    "        #设置y轴范围\n",
    "        #self.plt.ylim(-5,100)\n",
    "        ax.set_title(\"Model loss\")\n",
    "        ax.set_xlabel(\"Epoch\")\n",
    "        ax.set_ylabel(\"Loss\")\n",
    "        ax.legend([\"Train\", \"Validation\"], loc=\"upper right\")\n",
    "\n",
    "    def save_figure(self, name):\n",
    "        \"\"\"\n",
    "        Save figure.\n",
    "        name : str\n",
    "            save png file path.\n",
    "        return : None\n",
    "        \"\"\"\n",
    "        self.plt.savefig(name)\n",
    "\n",
    "\n",
    "########################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def list_to_vector_array(file_list,\n",
    "                         msg=\"calc...\",\n",
    "                         n_mels=64,\n",
    "                         frames=5,\n",
    "                         n_fft=1024,\n",
    "                         hop_length=512,\n",
    "                         power=2.0):\n",
    "    \"\"\"\n",
    "    convert the file_list to a vector array.\n",
    "    file_to_vector_array() is iterated, and the output vector array is concatenated.\n",
    "    file_list : list [ str ]\n",
    "        .wav filename list of dataset\n",
    "    msg : str ( default = \"calc...\" )\n",
    "        description for tqdm.\n",
    "        this parameter will be input into \"desc\" param at tqdm.\n",
    "    return : numpy.array( numpy.array( float ) )\n",
    "        vector array for training (this function is not used for test.)\n",
    "        * dataset.shape = (number of feature vectors, dimensions of feature vectors)\n",
    "    \"\"\"\n",
    "    # calculate the number of dimensions\n",
    "    dims = n_mels * frames\n",
    "\n",
    "    # iterate file_to_vector_array()\n",
    "    for idx in tqdm(range(len(file_list)), desc=msg):\n",
    "        vector_array = com.file_to_vector_array(file_list[idx],\n",
    "                                                n_mels=n_mels,\n",
    "                                                frames=frames,\n",
    "                                                n_fft=n_fft,\n",
    "                                                hop_length=hop_length,\n",
    "                                                power=power)\n",
    "        if idx == 0:\n",
    "            dataset = numpy.zeros((vector_array.shape[0] * len(file_list), dims), float)\n",
    "        dataset[vector_array.shape[0] * idx: vector_array.shape[0] * (idx + 1), :] = vector_array\n",
    "\n",
    "    return dataset\n",
    "\n",
    "def file_list_generator(target_dir,\n",
    "                        dir_name=\"train\",\n",
    "                        ext=\"wav\"):\n",
    "    \"\"\"\n",
    "    target_dir : str\n",
    "        base directory path of the dev_data or eval_data\n",
    "    dir_name : str (default=\"train\")\n",
    "        directory name containing training data\n",
    "    ext : str (default=\"wav\")\n",
    "        file extension of audio files\n",
    "    return :\n",
    "        train_files : list [ str ]\n",
    "            file list for training\n",
    "    \"\"\"\n",
    "    com.logger.info(\"target_dir : {}\".format(target_dir))\n",
    "\n",
    "    # generate training list\n",
    "    training_list_path = os.path.abspath(\"{dir}/{dir_name}/*.{ext}\".format(dir=target_dir, dir_name=dir_name, ext=ext))\n",
    "    files = sorted(glob.glob(training_list_path))\n",
    "    if len(files) == 0:\n",
    "        com.logger.exception(\"no_wav_file!!\")\n",
    "\n",
    "    com.logger.info(\"train_file num : {num}\".format(num=len(files)))\n",
    "    return files\n",
    "\n",
    "def fetch_dataloaders(files,radio = 0.9,batchsize=512):\n",
    "    len_d = len(files)\n",
    "    num_sample_train = int(len_d * radio)\n",
    "    index = list(range(len_d))\n",
    "    random.shuffle(files)\n",
    "    train = list(files[0:num_sample_train])\n",
    "    val = list(files[num_sample_train+1:])\n",
    "    train_data_loader = torch.utils.data.DataLoader(dataset=train, batch_size=batchsize, shuffle=True)\n",
    "    val_data_loader = torch.utils.data.DataLoader(dataset=val, batch_size=batchsize, shuffle=True)\n",
    "    loader = {}\n",
    "    loader['train'] = train_data_loader\n",
    "    loader['val'] = val_data_loader\n",
    "    return loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "########################################################################\n",
    "#pytorch 模型相关\n",
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AutoEncoder, self).__init__()\n",
    "\n",
    "        # Encoder\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(640, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 32),\n",
    "        )\n",
    "\n",
    "        # Decoder\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(32, 32),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 64),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 640),\n",
    "        )\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        codes = self.encoder(inputs)\n",
    "        decoded = self.decoder(codes)\n",
    "\n",
    "        return codes, decoded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-21 14:56:30,537 - INFO - target_dir : ../file/noise_detect\n",
      "2021-10-21 14:56:30,539 - INFO - train_file num : 200\n",
      "2021-10-21 14:56:30,540 - INFO - files num 200\n",
      "generate train_dataset: 100%|██████████| 200/200 [00:03<00:00, 53.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============== MODEL TRAINING ==============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-21 14:56:34,288 - INFO - train_data num 11800\n",
      "2021-10-21 14:56:34,507 - INFO - epoch = 10\n",
      "100%|██████████| 21/21 [00:00<00:00, 29.76it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 56.56it/s]\n",
      "2021-10-21 14:56:35,272 - INFO - loss:345.2585754394531 epoch:0\n",
      "100%|██████████| 21/21 [00:00<00:00, 29.30it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 56.26it/s]\n",
      "2021-10-21 14:56:36,048 - INFO - loss:291.1200866699219 epoch:1\n",
      "100%|██████████| 21/21 [00:00<00:00, 28.99it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 60.64it/s]\n",
      "2021-10-21 14:56:36,830 - INFO - loss:236.2063751220703 epoch:2\n",
      "100%|██████████| 21/21 [00:00<00:00, 32.67it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 56.98it/s]\n",
      "2021-10-21 14:56:37,532 - INFO - loss:193.18788146972656 epoch:3\n",
      "100%|██████████| 21/21 [00:00<00:00, 29.40it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 61.19it/s]\n",
      "2021-10-21 14:56:38,305 - INFO - loss:184.3303680419922 epoch:4\n",
      "100%|██████████| 21/21 [00:00<00:00, 29.14it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 65.53it/s]\n",
      "2021-10-21 14:56:39,078 - INFO - loss:159.27993774414062 epoch:5\n",
      "100%|██████████| 21/21 [00:00<00:00, 29.52it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 58.10it/s]\n",
      "2021-10-21 14:56:39,847 - INFO - loss:142.92466735839844 epoch:6\n",
      "100%|██████████| 21/21 [00:00<00:00, 30.10it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 56.38it/s]\n",
      "2021-10-21 14:56:40,603 - INFO - loss:122.12994384765625 epoch:7\n",
      "100%|██████████| 21/21 [00:00<00:00, 29.20it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 58.04it/s]\n",
      "2021-10-21 14:56:41,378 - INFO - loss:91.79891967773438 epoch:8\n",
      "100%|██████████| 21/21 [00:00<00:00, 33.99it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 68.89it/s]\n",
      "2021-10-21 14:56:42,043 - INFO - loss:90.94267272949219 epoch:9\n",
      "C:\\ZTTTX\\Programing\\Anaconda\\envs\\noise_detect\\lib\\site-packages\\torch\\serialization.py:292: UserWarning: Couldn't retrieve source code for container of type AutoEncoder. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "C:\\ZTTTX\\Programing\\Anaconda\\envs\\noise_detect\\lib\\site-packages\\torch\\serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Sequential. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "C:\\ZTTTX\\Programing\\Anaconda\\envs\\noise_detect\\lib\\site-packages\\torch\\serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Linear. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "C:\\ZTTTX\\Programing\\Anaconda\\envs\\noise_detect\\lib\\site-packages\\torch\\serialization.py:292: UserWarning: Couldn't retrieve source code for container of type BatchNorm1d. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "C:\\ZTTTX\\Programing\\Anaconda\\envs\\noise_detect\\lib\\site-packages\\torch\\serialization.py:292: UserWarning: Couldn't retrieve source code for container of type ReLU. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============== END TRAINING ==============\n"
     ]
    }
   ],
   "source": [
    "\n",
    "########################################################################\n",
    "# \n",
    "########################################################################\n",
    "if __name__ == \"__main__\":\n",
    "    param = com.yaml_load()\n",
    "    files = file_list_generator(param[\"train_dictionary\"],dir_name=\"train\")\n",
    "    com.logger.info('files num {num}'.format(num=len(files)))\n",
    "    train_data = list_to_vector_array(files,\n",
    "                                        msg=\"generate train_dataset\",\n",
    "                                        n_mels=param[\"feature\"][\"n_mels\"],\n",
    "                                        frames=param[\"feature\"][\"frames\"],\n",
    "                                        n_fft=param[\"feature\"][\"n_fft\"],\n",
    "                                        hop_length=param[\"feature\"][\"hop_length\"],\n",
    "                                        power=param[\"feature\"][\"power\"])\n",
    "    # train model\n",
    "    print(\"============== MODEL TRAINING ==============\")\n",
    "    train_data = torch.Tensor(train_data)\n",
    "    com.logger.info('train_data num {num}'.format(num=len(train_data)))\n",
    "    train_loader = fetch_dataloaders(train_data,radio = 0.9,batchsize = 512)\n",
    "    model = AutoEncoder()\n",
    "    model.train()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    loss_func = nn.MSELoss()\n",
    "    loss_his = []\n",
    "    val_loss_his = []\n",
    "    com.logger.info(\"epoch = {}\".format(param[\"epoch\"]))\n",
    "    for epoch in range(param[\"epoch\"]):\n",
    "        losses=[]\n",
    "        for data in tqdm(train_loader[\"train\"]):\n",
    "            optimizer.zero_grad()\n",
    "            inputs = data\n",
    "            feature,y = model(inputs)\n",
    "            loss = loss_func(y, inputs)\n",
    "            losses.append(loss.data)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        loss_his.append(numpy.mean(losses))\n",
    "        val_losses=[]\n",
    "        for data in tqdm(train_loader[\"val\"]):\n",
    "            inputs = data\n",
    "            feature,y = model(inputs)\n",
    "            loss = loss_func(y, inputs)\n",
    "            val_losses.append(loss.data)\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "        val_loss_his.append(numpy.mean(val_losses))\n",
    "        com.logger.info(\"loss:{} epoch:{}\".format(loss,epoch))\n",
    "\n",
    "    \n",
    "    torch.save(model, param[\"model_file\"])\n",
    "    one_visualizer = visualizer()\n",
    "    one_visualizer.loss_plot(loss_his, val_loss_his)\n",
    "    one_visualizer.save_figure(r'pic/train/'+\"debug_tag{}_\".format(str(param[\"debug_tag\"]))+\"trainloss_his.png\")\n",
    "    print(\"============== END TRAINING ==============\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21/21 [00:00<00:00, 73.18it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "features = []\n",
    "for data in tqdm(train_loader[\"train\"]):\n",
    "    inputs = data\n",
    "    feature, y = model(inputs)\n",
    "    for one_feature in feature:\n",
    "        features.append(one_feature)\n",
    "numpy.save(param[\"normal_feature_dic\"],numpy.array(features))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c0c2945573aa59c6a6573181f2c456b961af40bf85fd5f702d7d7d22d6c12cb8"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
